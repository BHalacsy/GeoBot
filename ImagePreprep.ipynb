{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here we do preprocessing for our images to be used in our model.\n",
    "First lets import the images."
   ],
   "id": "29674b6f47a0af47"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-08T10:06:41.732190Z",
     "start_time": "2025-03-08T10:06:41.544556Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "dataset = r\"C:\\Users\\balin\\IdeaProjects\\GeoBot\\dataset\"\n",
    "imgdata = []\n",
    "\n",
    "\n",
    "for country in os.listdir(dataset):\n",
    "    pathToCountry = os.path.join(dataset, country)\n",
    "    if not os.path.isdir(pathToCountry):\n",
    "        continue\n",
    "\n",
    "    images = os.listdir(pathToCountry)\n",
    "    imageCount = len(images)\n",
    "\n",
    "    if imageCount < 30 or imageCount > 10000:\n",
    "        continue\n",
    "\n",
    "    for i in images:\n",
    "        pathToImage = os.path.join(pathToCountry, i)\n",
    "        imgdata.append((pathToImage, country))\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we read in the images and removed outliers. We can look into preprocessing the images for our ML model.",
   "id": "4a853b905c72b089"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T10:06:41.820432Z",
     "start_time": "2025-03-08T10:06:41.736179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def prepImg(path, resize=(224, 224)):\n",
    "    img = cv2.imread(path)\n",
    "\n",
    "    if img:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, resize)\n",
    "        img = img / 255\n",
    "\n",
    "    return img"
   ],
   "id": "fef7c3760ea91440",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T10:07:25.940690Z",
     "start_time": "2025-03-08T10:07:25.936014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encodedLabels = encoder.fit([country for img, country in imgdata])\n",
    "encodedImgData = []\n",
    "\n",
    "for i in range(len(imgdata)):\n",
    "    path, _ = imgdata[i]\n",
    "    path = prepImg(path)\n",
    "    if path:\n",
    "        label = encodedLabels[i]\n",
    "        encodedImgData.append((path, label))\n",
    "    else:\n",
    "        print(\"preprocessing error\")"
   ],
   "id": "c2ef588e56ea8e34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Awesome. So now we have our data all prepped, lets get our hands dirty with some ML\n",
   "id": "ae6e7e0afeb6fabf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We first split the data into training and testing.",
   "id": "6d8444c42163e841"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainData, testData = train_test_split(encodedImgData, test_size=0.2, random_state=42)\n",
    "\n"
   ],
   "id": "1947e01d8c2ffb4b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
